

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Scrapy at a glance &mdash; Scrapy 1.2.0dev2 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Scrapy 1.2.0dev2 documentation" href="../index.html"/>
        <link rel="next" title="Installation guide" href="install.html"/>
        <link rel="prev" title="Scrapy 1.2 documentation" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
              <div class="version">
                1.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">First steps</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Scrapy at a glance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#walk-through-of-an-example-spider">Walk-through of an example spider</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#what-just-happened">What just happened?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#what-else">What else?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-s-next">What&#8217;s next?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>Scrapy at a glance</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/intro/overview.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="scrapy-at-a-glance">
<span id="intro-overview"></span><h1>Scrapy at a glance<a class="headerlink" href="#scrapy-at-a-glance" title="Permalink to this headline">¶</a></h1>
<p>Scrapy is an application framework for crawling web sites and extracting
structured data which can be used for a wide range of useful applications, like
data mining, information processing or historical archival.</p>
<p>Even though Scrapy was originally designed for <a class="reference external" href="https://en.wikipedia.org/wiki/Web_scraping">web scraping</a>, it can also be
used to extract data using APIs (such as <a class="reference external" href="https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html">Amazon Associates Web Services</a>) or
as a general purpose web crawler.</p>
<div class="section" id="walk-through-of-an-example-spider">
<h2>Walk-through of an example spider<a class="headerlink" href="#walk-through-of-an-example-spider" title="Permalink to this headline">¶</a></h2>
<p>In order to show you what Scrapy brings to the table, we&#8217;ll walk you through an
example of a Scrapy Spider using the simplest way to run a spider.</p>
<p>So, here&#8217;s the code for a spider that follows the links to the top
voted questions on StackOverflow and scrapes some data from each page:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">StackOverflowSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;stackoverflow&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://stackoverflow.com/questions?sort=votes&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.question-summary h3 a::attr(href)&#39;</span><span class="p">):</span>
            <span class="n">full_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">href</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">full_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_question</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_question</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;h1 a::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
            <span class="s1">&#39;votes&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.question .vote-count-post::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
            <span class="s1">&#39;body&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.question .post-text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
            <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.question .post-tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="s1">&#39;link&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">,</span>
        <span class="p">}</span>
</pre></div>
</div>
<p>Put this in a file, name it to something like <code class="docutils literal"><span class="pre">stackoverflow_spider.py</span></code>
and run the spider using the <a class="reference internal" href="../topics/commands.html#std:command-runspider"><code class="xref std std-command docutils literal"><span class="pre">runspider</span></code></a> command:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">runspider</span> <span class="n">stackoverflow_spider</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">o</span> <span class="n">top</span><span class="o">-</span><span class="n">stackoverflow</span><span class="o">-</span><span class="n">questions</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
<p>When this finishes you will have in the <code class="docutils literal"><span class="pre">top-stackoverflow-questions.json</span></code> file
a list of the most upvoted questions in StackOverflow in JSON format, containing the
title, link, number of upvotes, a list of the tags and the question content in HTML,
looking like this (reformatted for easier reading):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[{</span>
    <span class="s2">&quot;body&quot;</span><span class="p">:</span> <span class="s2">&quot;... LONG HTML HERE ...&quot;</span><span class="p">,</span>
    <span class="s2">&quot;link&quot;</span><span class="p">:</span> <span class="s2">&quot;http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;java&quot;</span><span class="p">,</span> <span class="s2">&quot;c++&quot;</span><span class="p">,</span> <span class="s2">&quot;performance&quot;</span><span class="p">,</span> <span class="s2">&quot;optimization&quot;</span><span class="p">],</span>
    <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Why is processing a sorted array faster than an unsorted array?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;votes&quot;</span><span class="p">:</span> <span class="s2">&quot;9924&quot;</span>
<span class="p">},</span>
<span class="p">{</span>
    <span class="s2">&quot;body&quot;</span><span class="p">:</span> <span class="s2">&quot;... LONG HTML HERE ...&quot;</span><span class="p">,</span>
    <span class="s2">&quot;link&quot;</span><span class="p">:</span> <span class="s2">&quot;http://stackoverflow.com/questions/1260748/how-do-i-remove-a-git-submodule&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;git&quot;</span><span class="p">,</span> <span class="s2">&quot;git-submodules&quot;</span><span class="p">],</span>
    <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;How do I remove a Git submodule?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;votes&quot;</span><span class="p">:</span> <span class="s2">&quot;1764&quot;</span>
<span class="p">},</span>
<span class="o">...</span><span class="p">]</span>
</pre></div>
</div>
<div class="section" id="what-just-happened">
<h3>What just happened?<a class="headerlink" href="#what-just-happened" title="Permalink to this headline">¶</a></h3>
<p>When you ran the command <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">runspider</span> <span class="pre">somefile.py</span></code>, Scrapy looked for a
Spider definition inside it and ran it through its crawler engine.</p>
<p>The crawl started by making requests to the URLs defined in the <code class="docutils literal"><span class="pre">start_urls</span></code>
attribute (in this case, only the URL for StackOverflow top questions page)
and called the default callback method <code class="docutils literal"><span class="pre">parse</span></code>, passing the response object as
an argument. In the <code class="docutils literal"><span class="pre">parse</span></code> callback we extract the links to the
question pages using a CSS Selector with a custom extension that allows to get
the value for an attribute. Then we yield a few more requests to be sent,
registering the method <code class="docutils literal"><span class="pre">parse_question</span></code> as the callback to be called for each
of them as they finish.</p>
<p>Here you notice one of the main advantages about Scrapy: requests are
<a class="reference internal" href="../topics/architecture.html#topics-architecture"><span class="std std-ref">scheduled and processed asynchronously</span></a>.  This
means that Scrapy doesn&#8217;t need to wait for a request to be finished and
processed, it can send another request or do other things in the meantime. This
also means that other requests can keep going even if some request fails or an
error happens while handling it.</p>
<p>While this enables you to do very fast crawls (sending multiple concurrent
requests at the same time, in a fault-tolerant way) Scrapy also gives you
control over the politeness of the crawl through <a class="reference internal" href="../topics/settings.html#topics-settings-ref"><span class="std std-ref">a few settings</span></a>. You can do things like setting a download delay between
each request, limiting amount of concurrent requests per domain or per IP, and
even <a class="reference internal" href="../topics/autothrottle.html#topics-autothrottle"><span class="std std-ref">using an auto-throttling extension</span></a> that tries
to figure out these automatically.</p>
<p>Finally, the <code class="docutils literal"><span class="pre">parse_question</span></code> callback scrapes the question data for each
page yielding a dict, which Scrapy then collects and writes to a JSON file as
requested in the command line.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This is using <a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"><span class="std std-ref">feed exports</span></a> to generate the
JSON file, you can easily change the export format (XML or CSV, for example) or the
storage backend (FTP or <a class="reference external" href="https://aws.amazon.com/s3/">Amazon S3</a>, for example).  You can also write an
<a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><span class="std std-ref">item pipeline</span></a> to store the items in a database.</p>
</div>
</div>
</div>
<div class="section" id="what-else">
<span id="topics-whatelse"></span><h2>What else?<a class="headerlink" href="#what-else" title="Permalink to this headline">¶</a></h2>
<p>You&#8217;ve seen how to extract and store items from a website using Scrapy, but
this is just the surface. Scrapy provides a lot of powerful features for making
scraping easy and efficient, such as:</p>
<ul>
<li><p class="first">Built-in support for <a class="reference internal" href="../topics/selectors.html#topics-selectors"><span class="std std-ref">selecting and extracting</span></a> data
from HTML/XML sources using extended CSS selectors and XPath expressions,
with helper methods to extract using regular expressions.</p>
</li>
<li><p class="first">An <a class="reference internal" href="../topics/shell.html#topics-shell"><span class="std std-ref">interactive shell console</span></a> (IPython aware) for trying
out the CSS and XPath expressions to scrape data, very useful when writing or
debugging your spiders.</p>
</li>
<li><p class="first">Built-in support for <a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"><span class="std std-ref">generating feed exports</span></a> in
multiple formats (JSON, CSV, XML) and storing them in multiple backends (FTP,
S3, local filesystem)</p>
</li>
<li><p class="first">Robust encoding support and auto-detection, for dealing with foreign,
non-standard and broken encoding declarations.</p>
</li>
<li><p class="first"><a class="reference internal" href="../index.html#extending-scrapy"><span class="std std-ref">Strong extensibility support</span></a>, allowing you to plug
in your own functionality using <a class="reference internal" href="../topics/signals.html#topics-signals"><span class="std std-ref">signals</span></a> and a
well-defined API (middlewares, <a class="reference internal" href="../topics/extensions.html#topics-extensions"><span class="std std-ref">extensions</span></a>, and
<a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><span class="std std-ref">pipelines</span></a>).</p>
</li>
<li><dl class="first docutils">
<dt>Wide range of built-in extensions and middlewares for handling:</dt>
<dd><ul class="first last simple">
<li>cookies and session handling</li>
<li>HTTP features like compression, authentication, caching</li>
<li>user-agent spoofing</li>
<li>robots.txt</li>
<li>crawl depth restriction</li>
<li>and more</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">A <a class="reference internal" href="../topics/telnetconsole.html#topics-telnetconsole"><span class="std std-ref">Telnet console</span></a> for hooking into a Python
console running inside your Scrapy process, to introspect and debug your
crawler</p>
</li>
<li><p class="first">Plus other goodies like reusable spiders to crawl sites from <a class="reference external" href="http://www.sitemaps.org">Sitemaps</a> and
XML/CSV feeds, a media pipeline for <a class="reference internal" href="../topics/media-pipeline.html#topics-media-pipeline"><span class="std std-ref">automatically downloading images</span></a> (or any other media) associated with the scraped
items, a caching DNS resolver, and much more!</p>
</li>
</ul>
</div>
<div class="section" id="what-s-next">
<h2>What&#8217;s next?<a class="headerlink" href="#what-s-next" title="Permalink to this headline">¶</a></h2>
<p>The next steps for you are to <a class="reference internal" href="install.html#intro-install"><span class="std std-ref">install Scrapy</span></a>,
<a class="reference internal" href="tutorial.html#intro-tutorial"><span class="std std-ref">follow through the tutorial</span></a> to learn how to organize
your code in Scrapy projects and <a class="reference external" href="http://scrapy.org/community/">join the community</a>. Thanks for your
interest!</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="install.html" class="btn btn-neutral float-right" title="Installation guide" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral" title="Scrapy 1.2 documentation" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008-2016, Scrapy developers.
      Last updated on Jul 03, 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.2.0dev2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>